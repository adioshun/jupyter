{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Building Safe A.I.\n",
    "출처 : [I am trask](https://iamtrask.github.io/2017/03/17/safe-ai/)\n",
    "\n",
    "- we're going to train a neural network that is fully encrypted during training (trained on unencrypted data). \n",
    "- The result will be a neural network with two beneficial properties.\n",
    "    1. 뉴럴 네트워크의 intelligence를 보호 할수 있음.  \n",
    "    2. 뉴럴 네트워크는 암호화된 Prediction만 수행함 the network can only make encrypted predictions (which presumably have no impact on the outside world because the outside world cannot understand the predictions without a secret key).\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: What is Deep Learning?\n",
    "The big takeaway here is this `error signal`. Without being told how well it's predictions are, it cannot learn. This will be important to remember.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: What is Homomorphic Encryption?\n",
    "\n",
    "As the name suggests, Homomorphic Encryption is a form of encryption. \n",
    "\n",
    "In the asymmetric case, \n",
    "- it can take perfectly readable text and turn it into jibberish using a \"public key\". \n",
    "- it can then take that jibberish and turn it back into the same text using a \"secret key\". \n",
    "\n",
    "However, unless you have the \"secret key\", you cannot decode the jibberish (in theory).\n",
    "\n",
    "Homomorphic Encryption is a special type of encryption though. \n",
    "\n",
    "It allows someone to modify the encrypted information in specific ways without being able to read the information. \n",
    "- For example, homomorphic encryption can be performed on numbers such that multiplication and addition can be performed on encrypted values without decrypting them. \n",
    "\n",
    "Here are a few toy examples.\n",
    "\n",
    "![](https://iamtrask.github.io/img/he.png)\n",
    "\n",
    "It's a relatively young field and there are several significant problems\n",
    "\n",
    "For now, let's just start with the following. \n",
    "\n",
    "- Integer public key encryption schemes that are homomorphic over multiplication and addition can perform the operations in the picture above. \n",
    "\n",
    "- Furthermore, because the public key allows for \"one way\" encryption, you can even perform operations between unencrypted numbers and encrypted numbers (by one-way encrypting them), as exemplified above by 2 * Cypher A. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Can we use them together?\n",
    "참고 자료\n",
    "- Crypto-Nets: Neural Networks over Encrypted Data, 2014, [[링크]](https://arxiv.org/abs/1412.6181)\n",
    "- [Encrypted Data For Efficient Markets](https://medium.com/numerai/encrypted-data-for-efficient-markets-fffbe9743ba8#.ov04s32h2)\n",
    "- [Hacker Lexicon: What Is Homomorphic Encryption?](https://www.wired.com/2014/11/hacker-lexicon-homomorphic-encryption/)\n",
    "\n",
    "Perhaps the most frequent intersection between Deep Learning and Homomorphic Encryption has manifested around Data Privacy. \n",
    "\n",
    "As it turns out, when you homomorphically encrypt data, you can't read it but you still maintain most of the interesting statistical structure. \n",
    "\n",
    "__This has allowed people to train models on encrypted data (CryptoNets). __\n",
    "\n",
    "Furthermore a startup hedge fund called Numer.ai encrypts expensive, proprietary data and allows anyone to attempt to train machine learning models to predict the stock market. \n",
    "\n",
    "Normally they wouldn't be able to do this becuase it would constitute giving away incredibly expensive information. (and normal encryption would make model training impossible)\n",
    "\n",
    "However, this blog post is about doing the inverse, encrypting the neural network and training it on decrypted data.\n",
    "\n",
    "A neural network, in all its amazing complexity, actually breaks down into a surprisingly small number of moving parts which are simply repeated over and over again. \n",
    "\n",
    "In fact, many state-of-the-art neural networks can be created using only the following operations:\n",
    "- Addition\n",
    "- Multiplication\n",
    "- Division\n",
    "- Subtraction\n",
    "- Sigmoid\n",
    "- Tanh\n",
    "- Exponential\n",
    "\n",
    "So, let's ask the obvious technical question, can we homomorphically encrypt the neural network itself? Would we want to? As it turns out, with a few conservative approximations, this can be done.\n",
    "- Addition - works out of the box\n",
    "- Multiplication - works out of the box\n",
    "- Division - works out of the box? - simply 1 / multiplication\n",
    "- Subtraction - works out of the box? - simply negated addition\n",
    "- Sigmoid - hmmm... perhaps a bit harder\n",
    "- Tanh - hmmm... perhaps a bit harder\n",
    "- Exponential - hmmm... perhaps a bit harder\n",
    "\n",
    "It seems like we'll be able to get Division and Subtraction pretty trivially, but these more complicated functions are... well... more complicated than simple addition and multiplication. \n",
    "\n",
    "In order to try to homomorphically encrypt a deep neural network, we need one more secret ingredient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Taylor Series Expansion\n",
    "\n",
    "Perhaps you remember it from primary school. \n",
    "\n",
    "A Taylor Series allows one to compute a complicated (nonlinear) function using an infinite series of additions, subtractions, multiplications, and divisions. \n",
    "\n",
    "Fortunately, if you stop short of computing the exact Taylor Series Expansion you can still get a close approximation of the function at hand. \n",
    "\n",
    "Here are a few popular functions approximated via Taylor Series.\n",
    "\n",
    "![](https://iamtrask.github.io/img/taylor_series.gif)\n",
    "\n",
    "WAIT! THERE ARE EXPONENTS! \n",
    "\n",
    "No worries. Exponents are just repeated multiplication, which we can do. \n",
    "\n",
    "For something to play with, here's a little python implementation approximating the Taylor Series for our desirable sigmoid function. \n",
    "\n",
    "We'll take the first few parts of the series and see how close we get to the true sigmoid function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input:0.1\n",
      "Exact Sigmoid:0.524979187479\n",
      "Approx Sigmoid:0.0249791875\n",
      "\n",
      "Input:0.2\n",
      "Exact Sigmoid:0.549833997312\n",
      "Approx Sigmoid:0.049834\n",
      "\n",
      "Input:0.3\n",
      "Exact Sigmoid:0.574442516812\n",
      "Approx Sigmoid:0.0744425625\n",
      "\n",
      "Input:0.4\n",
      "Exact Sigmoid:0.598687660112\n",
      "Approx Sigmoid:0.098688\n",
      "\n",
      "Input:0.5\n",
      "Exact Sigmoid:0.622459331202\n",
      "Approx Sigmoid:0.1224609375\n",
      "\n",
      "Input:0.6\n",
      "Exact Sigmoid:0.645656306226\n",
      "Approx Sigmoid:0.145662\n",
      "\n",
      "Input:0.7\n",
      "Exact Sigmoid:0.668187772168\n",
      "Approx Sigmoid:0.1682043125\n",
      "\n",
      "Input:0.8\n",
      "Exact Sigmoid:0.689974481128\n",
      "Approx Sigmoid:0.190016\n",
      "\n",
      "Input:0.9\n",
      "Exact Sigmoid:0.710949502625\n",
      "Approx Sigmoid:0.2110426875\n",
      "\n",
      "Input:1.0\n",
      "Exact Sigmoid:0.73105857863\n",
      "Approx Sigmoid:0.23125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid_exact(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# using taylor series\n",
    "def sigmoid_approximation(x):\n",
    "  return (1 / 2) + (x / 4) - (x**3 / 48) + (x**5 / 480)\n",
    "\n",
    "for lil_number in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "  \n",
    "  print(\"\\nInput:\" + str(lil_number))\n",
    "  print(\"Exact Sigmoid:\" + str(sigmoid_exact(lil_number)))\n",
    "  print(\"Approx Sigmoid:\" + str(sigmoid_approximation(lil_number)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only the first four factors of the Taylor Series, we get very close to sigmoid for a relatively large series of numbers. \n",
    "\n",
    "Now that we have our general strategy, it's time to select a Homomorphic Encryption algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Choosing an Encryption Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "116px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
